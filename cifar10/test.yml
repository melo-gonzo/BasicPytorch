model:
  num_classes: 10
data:
  data_dir: ./data
  batch_size: 16
optimizer:
  class_path: torch.optim.adam.Adam
  init_args:
    lr: 0.0005
lr_scheduler:
  class_path: torch.optim.lr_scheduler.ExponentialLR
  init_args:
    gamma: 0.1
trainer:
  max_epochs: 100
  accelerator: "gpu"
  gpus: 1
  num_nodes: 1
  enable_checkpointing: False
  strategy: null
  callbacks:
    - class_path: pytorch_lightning.callbacks.EarlyStopping
      init_args:
        patience: 5
        monitor: val_loss
        mode: min
seed_everything: 42
# python -m main_cli fit --config ./test.yml
# python -m main fit --config ./test.yml

